{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahny678/Performance-Analysis-of-Lightweight-CNN-models-/blob/main/PERFORMANCE_ANALYSIS_ON_CROP_DS_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozLtjmAvOLQk"
      },
      "source": [
        "IMPORTING AND PROCESSING DATA..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptdgs_seN_nB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPJGJMgnOQx-"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LHouuJdOVVZ"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "base_dir = '/content/drive/MyDrive/PERFORMANCECROPDATASET'\n",
        "maize_dir = os.path.join(base_dir, 'Maize')\n",
        "rice_dir = os.path.join(base_dir, 'Rice')\n",
        "sorghum_dir = os.path.join(base_dir, 'Sorghum')\n",
        "\n",
        "# Image parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe8PP7NYOtK3"
      },
      "outputs": [],
      "source": [
        "# Function to verify dataset structure\n",
        "def verify_dataset_structure(dataset_dir, dataset_name):\n",
        "    print(f\"\\nVerifying {dataset_name} dataset structure...\")\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        split_dir = os.path.join(dataset_dir, split)\n",
        "        if not os.path.exists(split_dir):\n",
        "            print(f\"Error: {split_dir} does not exist!\")\n",
        "            continue\n",
        "        classes = os.listdir(split_dir)\n",
        "        print(f\"{split.capitalize()} set: {len(classes)} classes\")\n",
        "        for cls in classes:\n",
        "            cls_dir = os.path.join(split_dir, cls)\n",
        "            num_images = len(os.listdir(cls_dir))\n",
        "            print(f\"  {cls}: {num_images} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kjBEK4deO1x6"
      },
      "outputs": [],
      "source": [
        "# Verify dataset structure for all crops\n",
        "\n",
        "# verify_dataset_structure(maize_dir, \"Maize\")\n",
        "# verify_dataset_structure(rice_dir, \"Rice\")\n",
        "# verify_dataset_structure(sorghum_dir, \"Sorghum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_rixhxAO2mE"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXAfDRGPO4xS"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset\n",
        "def load_dataset(dataset_dir, split, shuffle=False):\n",
        "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(dataset_dir, split),\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "      label_mode='categorical'  # One-hot encoded labels\n",
        "    )\n",
        "    # Normalize to [0, 1]\n",
        "    dataset = dataset.map(lambda x, y: (x / 255.0, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if split == 'train':\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                             num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Convert to float32\n",
        "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), y),\n",
        "                         num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Cache and prefetch for performance\n",
        "    dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiEu0zOpPEod",
        "outputId": "ed9a2702-71ea-46b2-b01c-5ba1840ee279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2950 files belonging to 4 classes.\n",
            "Found 836 files belonging to 4 classes.\n",
            "Found 422 files belonging to 4 classes.\n",
            "Found 1830 files belonging to 6 classes.\n",
            "Found 389 files belonging to 6 classes.\n",
            "Found 400 files belonging to 6 classes.\n",
            "Found 5439 files belonging to 7 classes.\n",
            "Found 1560 files belonging to 7 classes.\n",
            "Found 782 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load datasets for each crop\n",
        "maize_train = load_dataset(maize_dir, 'train', shuffle=True)\n",
        "maize_val = load_dataset(maize_dir, 'validation')\n",
        "maize_test = load_dataset(maize_dir, 'test')\n",
        "\n",
        "rice_train = load_dataset(rice_dir, 'train', shuffle=True)\n",
        "rice_val = load_dataset(rice_dir, 'validation')\n",
        "rice_test = load_dataset(rice_dir, 'test')\n",
        "\n",
        "sorghum_train = load_dataset(sorghum_dir, 'train', shuffle=True)\n",
        "sorghum_val = load_dataset(sorghum_dir, 'validation')\n",
        "sorghum_test = load_dataset(sorghum_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOzL_laCPHKR"
      },
      "outputs": [],
      "source": [
        "# Function to compute class weights\n",
        "def compute_class_weights(dataset_dir, split, class_names):\n",
        "    class_counts = {}\n",
        "    split_dir = os.path.join(dataset_dir, split)\n",
        "    for cls in class_names:\n",
        "        cls_dir = os.path.join(split_dir, cls)\n",
        "        class_counts[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "    # Get class indices\n",
        "    labels = []\n",
        "    for cls in class_names:\n",
        "        count = class_counts[cls]\n",
        "        labels.extend([class_names.index(cls)] * count)\n",
        "\n",
        "    # Compute class weights\n",
        "    weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(labels),\n",
        "        y=labels\n",
        "    )\n",
        "    return dict(zip(range(len(class_names)), weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXkcqYnUPMTZ"
      },
      "outputs": [],
      "source": [
        "# Get class names for each dataset\n",
        "maize_class_names = sorted(os.listdir(os.path.join(maize_dir, 'train')))\n",
        "rice_class_names = sorted(os.listdir(os.path.join(rice_dir, 'train')))\n",
        "sorghum_class_names = sorted(os.listdir(os.path.join(sorghum_dir, 'train')))\n",
        "\n",
        "# Compute class weights for training sets\n",
        "maize_class_weights = compute_class_weights(maize_dir, 'train', maize_class_names)\n",
        "rice_class_weights = compute_class_weights(rice_dir, 'train', rice_class_names)\n",
        "sorghum_class_weights = compute_class_weights(sorghum_dir, 'train', sorghum_class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBYzPzE6OHpi",
        "outputId": "25894985-b87a-4110-9a32-42b668e3f605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Maize Class Weights: {0: np.float64(0.919576059850374), 1: np.float64(0.7981601731601732), 2: np.float64(1.839152119700748), 3: np.float64(0.8961117861482382)}\n",
            "Rice Class Weights: {0: np.float64(1.0166666666666666), 1: np.float64(0.9967320261437909), 2: np.float64(0.9967320261437909), 3: np.float64(0.9967320261437909), 4: np.float64(0.9967320261437909), 5: np.float64(0.9967320261437909)}\n",
            "Sorghum Class Weights: {0: np.float64(1.0959097320169253), 1: np.float64(0.9098360655737705), 2: np.float64(3.9846153846153847), 3: np.float64(2.226361031518625), 4: np.float64(0.4666666666666667), 5: np.float64(1.85), 6: np.float64(0.6230954290296712)}\n"
          ]
        }
      ],
      "source": [
        "# Print class weights\n",
        "print(\"\\nMaize Class Weights:\", maize_class_weights)\n",
        "print(\"Rice Class Weights:\", rice_class_weights)\n",
        "print(\"Sorghum Class Weights:\", sorghum_class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ_HyyNuCCyh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot class weights\n",
        "def plot_class_weights(class_weights, class_names, crop_name):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    weights = list(class_weights.values())\n",
        "    indices = list(class_weights.keys())\n",
        "\n",
        "    plt.bar(class_names, weights, color='skyblue')\n",
        "    plt.xlabel('Class Name')\n",
        "    plt.ylabel('Class Weight')\n",
        "    plt.title(f'{crop_name} Class Weights')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b33umO8PDmmp"
      },
      "outputs": [],
      "source": [
        "# # Plot for Maize\n",
        "plot_class_weights(maize_class_weights, maize_class_names, \"Maize\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ8mKoY6Dgo6"
      },
      "outputs": [],
      "source": [
        "# # Plot for Rice\n",
        "plot_class_weights(rice_class_weights, rice_class_names, \"Rice\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVHbXZ-xDioW"
      },
      "outputs": [],
      "source": [
        "# # Plot for Sorghum\n",
        "plot_class_weights(sorghum_class_weights, sorghum_class_names, \"Sorghum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MdiuaKJnPSzU"
      },
      "outputs": [],
      "source": [
        "# eg: Check a batch from maize_train\n",
        "for images, labels in maize_train.take(1):\n",
        "    print(\"\\nSample batch from Maize Train:\")\n",
        "    print(\"Image shape:\", images.shape)\n",
        "    print(\"Label shape:\", labels.shape)\n",
        "    print(\"Pixel range:\", tf.reduce_min(images).numpy(), tf.reduce_max(images).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPZBghgV_Iq"
      },
      "outputs": [],
      "source": [
        "# Import additional libraries\n",
        "from tensorflow.keras.applications import VGG16, MobileNetV3Small, DenseNet121, NASNetMobile, EfficientNetB2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwKTDdyIWMgS"
      },
      "outputs": [],
      "source": [
        "# Define output directory for saving models and plots\n",
        "output_dir = '/content/drive/MyDrive/crop_model_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nVFGGeOWOYU"
      },
      "outputs": [],
      "source": [
        "# Model configurations\n",
        "models_config = {\n",
        "    'VGG16': {\n",
        "        'base_model': VGG16,\n",
        "        'preprocess_fn': tf.keras.applications.vgg16.preprocess_input\n",
        "    },\n",
        "    'MobileNetV3': {\n",
        "        'base_model': MobileNetV3Small,\n",
        "        'preprocess_fn': tf.keras.applications.mobilenet_v3.preprocess_input\n",
        "    },\n",
        "    'DenseNet121': {\n",
        "        'base_model': DenseNet121,\n",
        "        'preprocess_fn': tf.keras.applications.densenet.preprocess_input\n",
        "    },\n",
        "    'NasNetMobile': {\n",
        "        'base_model': NASNetMobile,\n",
        "        'preprocess_fn': tf.keras.applications.nasnet.preprocess_input\n",
        "    },\n",
        "    'EfficientNetB2': {\n",
        "        'base_model': EfficientNetB2,\n",
        "        'preprocess_fn': tf.keras.applications.efficientnet.preprocess_input\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVAP15GKWXIq"
      },
      "outputs": [],
      "source": [
        "# # Function to build model\n",
        "def build_model(base_model_fn, preprocess_fn, num_classes, model_name):\n",
        "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze base model\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = preprocess_fn(inputs)  # Apply model-specific preprocessing\n",
        "    x = base_model(x, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G1KNMQtWfaX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def train_and_evaluate(train_ds, val_ds, test_ds, class_weights, num_classes, model_name, crop_name, preprocess_fn, class_names):\n",
        "    # Setup organized directories\n",
        "    crop_dir = os.path.join(output_dir, crop_name)\n",
        "    model_dir = os.path.join(crop_dir, model_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    # Build model\n",
        "    base_model_fn = models_config[model_name]['base_model']\n",
        "    model = build_model(base_model_fn, preprocess_fn, num_classes, f\"{crop_name}_{model_name}\")\n",
        "\n",
        "    # Preprocess datasets\n",
        "    train_ds_proc = train_ds.map(lambda x, y: (preprocess_fn(x * 255.0), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val_ds_proc = val_ds.map(lambda x, y: (preprocess_fn(x * 255.0), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    test_ds_proc = test_ds.map(lambda x, y: (preprocess_fn(x * 255.0), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    train_ds_proc = train_ds_proc.cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds_proc = val_ds_proc.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    test_ds_proc = test_ds_proc.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Checkpoint to save best model weights\n",
        "    checkpoint_path = os.path.join(model_dir, \"best_model.h5\")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_ds_proc,\n",
        "        validation_data=val_ds_proc,\n",
        "        epochs=EPOCHS,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Load best weights\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    # Save complete model\n",
        "    model.save(os.path.join(model_dir, \"full_model.keras\"))\n",
        "\n",
        "    # Evaluate on test data\n",
        "    test_loss, test_accuracy = model.evaluate(test_ds_proc)\n",
        "    print(f\"\\n{crop_name} {model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in test_ds_proc:\n",
        "        preds = model.predict(images)\n",
        "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "    # Classification report\n",
        "    report_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "    with open(os.path.join(model_dir, \"classification_report.json\"), \"w\") as f:\n",
        "        json.dump(report_dict, f, indent=4)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "    plt.title(f\"{crop_name} {model_name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Training history plots\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_dir, \"training_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Save training history\n",
        "    with open(os.path.join(model_dir, \"training_history.json\"), \"w\") as f:\n",
        "        json.dump(history.history, f, indent=4)\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14cRtLQ5Wqn5"
      },
      "outputs": [],
      "source": [
        "# Define crops and their datasets\n",
        "crops = [\n",
        "    {\n",
        "        'name': 'Maize',\n",
        "        'train_ds': maize_train,\n",
        "        'val_ds': maize_val,\n",
        "        'test_ds': maize_test,\n",
        "        'class_weights': maize_class_weights,\n",
        "        'num_classes': len(maize_class_names),\n",
        "        'class_names': maize_class_names\n",
        "    },\n",
        "    {\n",
        "        'name': 'Rice',\n",
        "        'train_ds': rice_train,\n",
        "        'val_ds': rice_val,\n",
        "        'test_ds': rice_test,\n",
        "        'class_weights': rice_class_weights,\n",
        "        'num_classes': len(rice_class_names),\n",
        "        'class_names': rice_class_names\n",
        "    },\n",
        "    {\n",
        "        'name': 'Sorghum',\n",
        "        'train_ds': sorghum_train,\n",
        "        'val_ds': sorghum_val,\n",
        "        'test_ds': sorghum_test,\n",
        "        'class_weights': sorghum_class_weights,\n",
        "        'num_classes': len(sorghum_class_names),\n",
        "        'class_names': sorghum_class_names\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7CU-YKmNlp4"
      },
      "source": [
        "MAIZE-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfVXqH2JV7ez"
      },
      "outputs": [],
      "source": [
        "model_name = 'VGG16'\n",
        "crop = crops[0]  # Maize\n",
        "\n",
        "model, history = train_and_evaluate(\n",
        "    crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "    crop['class_weights'], crop['num_classes'],\n",
        "    model_name, crop['name'],\n",
        "    models_config[model_name]['preprocess_fn'],\n",
        "    crop['class_names']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qox1ZsrcNyQQ"
      },
      "source": [
        "MAIZE-MOBILENETV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtQ1HZ-dNsQZ"
      },
      "outputs": [],
      "source": [
        "# model_name = 'MobileNetV3'\n",
        "# crop = crops[0]  # Maize\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKkMdEURN1_9"
      },
      "source": [
        "Maize - DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzQGKWMIN8Ld"
      },
      "outputs": [],
      "source": [
        "# model_name = 'DenseNet121'\n",
        "# crop = crops[0]  # Maize\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asqe48kjN_Zr"
      },
      "source": [
        "Maize - NasNetMobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6qSpv_OENo"
      },
      "outputs": [],
      "source": [
        "# model_name = 'NasNetMobile'\n",
        "# crop = crops[0]  # Maize\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSGaHSMYOGhv"
      },
      "source": [
        "Maize - EfficientNetB2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbwTxh4oOJ2b"
      },
      "outputs": [],
      "source": [
        "# model_name = 'EfficientNetB2'\n",
        "# crop = crops[0]  # Maize\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zofBz5tFOLs-"
      },
      "source": [
        "Rice - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2m5tFZVORie"
      },
      "outputs": [],
      "source": [
        "# model_name = 'VGG16'\n",
        "# crop = crops[1]  # Rice\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7oMtmQROTKJ"
      },
      "source": [
        "Rice - MobileNetV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrFWVfRUOWT3"
      },
      "outputs": [],
      "source": [
        "# model_name = 'MobileNetV3'\n",
        "# crop = crops[1]  # Rice\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXl2vGEPOY3D"
      },
      "source": [
        "Rice - DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK4xYpk-OcUz"
      },
      "outputs": [],
      "source": [
        "# model_name = 'DenseNet121'\n",
        "# crop = crops[1]  # Rice\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDarviK9OeXf"
      },
      "source": [
        "Rice - NasNetMobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00KWKEaHOhtZ"
      },
      "outputs": [],
      "source": [
        "# model_name = 'NasNetMobile'\n",
        "# crop = crops[1]  # Rice\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXGmyioFOsKj"
      },
      "source": [
        "Rice - EfficientNetB2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQkFyg0yOo0l"
      },
      "outputs": [],
      "source": [
        "# model_name = 'EfficientNetB2'\n",
        "# crop = crops[1]  # Rice\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mppQtQ9SO7Yt"
      },
      "source": [
        " Sorghum - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw1HQVp1O-Ca"
      },
      "outputs": [],
      "source": [
        "# model_name = 'VGG16'\n",
        "# crop = crops[2]  # Sorghum\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n",
        "# DIDNT COMPLETE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpX8LxVHO_23"
      },
      "source": [
        " Sorghum - MobileNetV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjvGMmXdPDBT"
      },
      "outputs": [],
      "source": [
        "# model_name = 'MobileNetV3'\n",
        "# crop = crops[2]  # Sorghum\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlJ6PfS4PEzQ"
      },
      "source": [
        "Sorghum - DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idwaUVA_PHmV"
      },
      "outputs": [],
      "source": [
        "# model_name = 'DenseNet121'\n",
        "# crop = crops[2]  # Sorghum\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBCwxBrcPLpI"
      },
      "source": [
        " Sorghum - NasNetMobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_u5BoV4PML2"
      },
      "outputs": [],
      "source": [
        "# model_name = 'NasNetMobile'\n",
        "# crop = crops[2]  # Sorghum\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec2XF-nIPQK9"
      },
      "source": [
        "Sorghum - EfficientNetB2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-93N8vJ_PQtN"
      },
      "outputs": [],
      "source": [
        "# model_name = 'EfficientNetB2'\n",
        "# crop = crops[2]  # Sorghum\n",
        "\n",
        "# model, history = train_and_evaluate(\n",
        "#     crop['train_ds'], crop['val_ds'], crop['test_ds'],\n",
        "#     crop['class_weights'], crop['num_classes'],\n",
        "#     model_name, crop['name'],\n",
        "#     models_config[model_name]['preprocess_fn'],\n",
        "#     crop['class_names']\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1eT_cnMX4r4CMOaVFKtBZjXiSdmkgMqzz",
      "authorship_tag": "ABX9TyPFVp+iU7AA9q6kb5tAVPqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}