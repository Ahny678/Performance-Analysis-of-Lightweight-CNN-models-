{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahny678/Performance-Analysis-of-Lightweight-CNN-models-/blob/main/PERFORMANCE_ANALYSIS_USING_BASIC_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7poxRxEdThui"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlDrXkoTwpI",
        "outputId": "61c3814f-7c9a-49fd-bd07-50bfd068ef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Relax TensorFlow error handling\n",
        "tf.data.experimental.enable_debug_mode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rA3u-T5U3f8"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "base_dir = '/content/drive/MyDrive/PERFORMANCECROPDATASET'\n",
        "maize_dir = os.path.join(base_dir, 'Maize')\n",
        "\n",
        "rice_dir = os.path.join(base_dir, 'Rice')\n",
        "sorghum_dir = os.path.join(base_dir, 'Sorghum')\n",
        "\n",
        "# Image parameters\n",
        "IMG_SIZE = (28, 28)  # Updated to match architecture\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Output directory for saving results\n",
        "output_base_dir = '/content/drive/MyDrive/PERFORMANCECROPDATASET_Hyper_Results'\n",
        "os.makedirs(output_base_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9XR-OJJU8so"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pzKRZVpUAZz"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset\n",
        "def load_dataset(dataset_dir, split, shuffle=False):\n",
        "    # image_dataset_from_directory automatically assigns labels based on directory names\n",
        "    # and returns class_names as an attribute of the dataset.\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        os.path.join(dataset_dir, split),\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        label_mode='categorical',\n",
        "        color_mode='grayscale'  # 1-channel input this time since its simple cnn\n",
        "    )\n",
        "\n",
        "    # Access class_names from the dataset object\n",
        "    class_names = dataset.class_names\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    dataset = dataset.map(lambda x, y: (x / 255.0, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if split == 'train':\n",
        "        # Ensure data augmentation is applied only during training\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                             num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Convert to float32 for model compatibility\n",
        "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), y),\n",
        "                         num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Cache and prefetch for performance\n",
        "    dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset, class_names # Return both dataset and class_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BELOW COMPUTE CLASS WEIGHTS FUNCTION REWRITTEN BY COLAB GEMINI DUE TO TF ERRORS..."
      ],
      "metadata": {
        "id": "2r7wtYFKtDOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to compute class weights using dataset's class names\n",
        "def compute_class_weights(dataset_dir, split, dataset_class_names):\n",
        "    class_counts = {}\n",
        "    split_dir = os.path.join(dataset_dir, split)\n",
        "\n",
        "    # Collect labels based on the actual class names and their integer index mapping\n",
        "    # as determined by image_dataset_from_directory\n",
        "    labels = []\n",
        "    for i, cls in enumerate(dataset_class_names):\n",
        "        cls_dir = os.path.join(split_dir, cls)\n",
        "        if os.path.exists(cls_dir):\n",
        "            # List all files in the directory, filtering out non-image files if necessary\n",
        "            # For simplicity, we count all entries assuming only image files or\n",
        "            # directories are present under class directories.\n",
        "            # A more robust approach would involve checking file extensions.\n",
        "            count = len([name for name in os.listdir(cls_dir) if os.path.isfile(os.path.join(cls_dir, name))])\n",
        "            class_counts[cls] = count\n",
        "            labels.extend([i] * count) # Use the index 'i' corresponding to the class name\n",
        "        else:\n",
        "             print(f\"Warning: Directory for class '{cls}' not found at {cls_dir}. Skipping.\")\n",
        "\n",
        "    if not labels:\n",
        "        print(f\"Warning: No samples found in {os.path.join(dataset_dir, split)}. Cannot compute class weights.\")\n",
        "        return {}\n",
        "\n",
        "    # Compute class weights using the actual integer labels found\n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    # compute_class_weight handles cases where some classes have zero samples in 'y'.\n",
        "    # It computes weights only for classes present in 'y'.\n",
        "    # The 'classes' argument should contain all possible class labels (0 to num_classes-1).\n",
        "    full_range_classes = list(range(len(dataset_class_names)))\n",
        "\n",
        "    # Check if unique_labels cover all expected classes\n",
        "    if len(unique_labels) < len(full_range_classes):\n",
        "        print(f\"Warning: Training data does not contain samples for all classes defined by dataset structure. Missing labels: {set(full_range_classes) - set(unique_labels)}\")\n",
        "        # In this case, compute_class_weight will only return weights for classes present in 'y'.\n",
        "        # We need to create a dictionary mapping from the full range of class indices\n",
        "        # to the computed weights, filling in missing weights (e.g., with 0 or a small value,\n",
        "        # though 0 is safer as it prevents the model from training on non-existent classes).\n",
        "        # Let's re-think how compute_class_weight should be used here.\n",
        "        # The function expects 'classes' to be the set of all possible class labels in 'y'.\n",
        "        # If 'y' contains labels [0, 1, 3] and classes=[0, 1, 2, 3], it will compute weights\n",
        "        # for 0, 1, and 3. The output is an array corresponding to the order of 'classes'.\n",
        "        # We need to ensure 'classes' argument is correct. It should be the unique labels found in 'y'.\n",
        "        # Or, if we want weights for all possible classes, we need to provide 'y' with\n",
        "        # representatives of all classes, which is not feasible from just the file counts.\n",
        "\n",
        "        # Let's use the unique labels found in the directory scan.\n",
        "        weights_array = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_labels, # Use the unique labels found in the data\n",
        "            y=labels\n",
        "        )\n",
        "        # Create a dictionary mapping the found unique labels to their weights\n",
        "        weight_dict = dict(zip(unique_labels, weights_array))\n",
        "\n",
        "        # Important: Keras model.fit 'class_weight' expects a dictionary mapping\n",
        "        # from CLASS INDEX (integer) to weight. The class indices should correspond\n",
        "        # to the order of class names returned by image_dataset_from_directory.\n",
        "        # So, the weight_dict should map 0 -> weight for class_names[0], 1 -> weight\n",
        "        # for class_names[1], etc., regardless of whether that class was present in 'labels'.\n",
        "        # This means we need to compute weights for all potential classes if we want\n",
        "        # a weight_dict that maps indices 0..num_classes-1 to weights.\n",
        "\n",
        "        # Let's revise: Compute weights for all classes based on their counts.\n",
        "        # The 'labels' list already represents the sample distribution across classes\n",
        "        # based on the directory structure. The indices in 'labels' correspond to\n",
        "        # the order in `dataset_class_names`.\n",
        "        all_class_indices = list(range(len(dataset_class_names)))\n",
        "        # compute_class_weight expects 'classes' to contain all unique labels in 'y'.\n",
        "        # If we want weights for all possible output classes (defined by dataset_class_names),\n",
        "        # we should pass those indices. If a class index in `all_class_indices` is not present\n",
        "        # in `labels`, compute_class_weight might raise an error or handle it based on\n",
        "        # its implementation. A safer approach is to only include classes present in `labels`\n",
        "        # in the `classes` argument, and then construct the weight dictionary for all\n",
        "        # possible classes, potentially assigning a default weight (e.g., 0 or 1) to missing ones.\n",
        "\n",
        "        # Let's stick to computing weights *only* for the classes actually found in the training data\n",
        "        # based on the directory scan, and then map these weights to the correct class indices.\n",
        "        # The `labels` list contains the integer indices corresponding to `dataset_class_names`.\n",
        "        # So, the unique labels in `labels` are exactly the indices of the classes present.\n",
        "        weights_array = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_labels, # These are the indices of classes present\n",
        "            y=labels\n",
        "        )\n",
        "        # Create the weight dictionary mapping class index (as found in 'labels') to weight\n",
        "        weight_dict = dict(zip(unique_labels, weights_array))\n",
        "\n",
        "        # Now, create a complete weight dictionary for all classes 0 to num_classes-1.\n",
        "        # If a class index is not in `unique_labels`, its weight is not computed.\n",
        "        # We should add these missing classes to the dictionary, perhaps with a weight of 0.\n",
        "        # However, using a weight of 0 for missing classes might be problematic if those\n",
        "        # classes actually exist in the validation/test sets.\n",
        "        # A more robust approach is to ensure the training set has at least one sample\n",
        "        # for each class that is expected to be in the dataset.\n",
        "        # Given the current setup, compute_class_weight returns weights for `unique_labels`.\n",
        "        # The `class_weight` argument in model.fit expects weights for classes 0 to num_classes-1.\n",
        "        # So, we need to map the computed weights for `unique_labels` to the full range of indices.\n",
        "        full_weight_dict = {i: 0.0 for i in range(len(dataset_class_names))} # Initialize all weights to 0\n",
        "        for idx, weight in weight_dict.items():\n",
        "            full_weight_dict[idx] = weight # Assign computed weights for existing classes\n",
        "\n",
        "        weight_dict_to_return = full_weight_dict\n",
        "\n",
        "    else:\n",
        "        # All classes expected based on `dataset_class_names` were found in `labels`.\n",
        "         weights_array = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_labels, # Use the unique labels found\n",
        "            y=labels\n",
        "        )\n",
        "         # Create the weight dictionary mapping class index to weight\n",
        "         weight_dict_to_return = dict(zip(unique_labels, weights_array))\n",
        "\n",
        "    return weight_dict_to_return"
      ],
      "metadata": {
        "id": "lZkuOG5NtJ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V_zFYWRUxI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4450ad64-f0b3-4cbc-ff18-55975417a20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2524 files belonging to 4 classes.\n",
            "Found 836 files belonging to 4 classes.\n",
            "Found 422 files belonging to 4 classes.\n",
            "Found 1830 files belonging to 6 classes.\n",
            "Found 389 files belonging to 6 classes.\n",
            "Found 400 files belonging to 6 classes.\n",
            "Found 5439 files belonging to 7 classes.\n",
            "Found 1560 files belonging to 7 classes.\n",
            "Found 782 files belonging to 7 classes.\n",
            "Warning: Training data does not contain samples for all classes defined by dataset structure. Missing labels: {2}\n"
          ]
        }
      ],
      "source": [
        "# Load datasets and capture class names for each crop\n",
        "maize_train, maize_class_names = load_dataset(maize_dir, 'train', shuffle=True)\n",
        "maize_val, _ = load_dataset(maize_dir, 'validation') # We only need class names from train split\n",
        "maize_test, _ = load_dataset(maize_dir, 'test')\n",
        "\n",
        "rice_train, rice_class_names = load_dataset(rice_dir, 'train', shuffle=True)\n",
        "rice_val, _ = load_dataset(rice_dir, 'validation')\n",
        "rice_test, _ = load_dataset(rice_dir, 'test')\n",
        "\n",
        "sorghum_train, sorghum_class_names = load_dataset(sorghum_dir, 'train', shuffle=True)\n",
        "sorghum_val, _ = load_dataset(sorghum_dir, 'validation')\n",
        "sorghum_test, _ = load_dataset(sorghum_dir, 'test')\n",
        "\n",
        "# Compute class weights using the captured class names\n",
        "maize_class_weights = compute_class_weights(maize_dir, 'train', maize_class_names)\n",
        "rice_class_weights = compute_class_weights(rice_dir, 'train', rice_class_names)\n",
        "sorghum_class_weights = compute_class_weights(sorghum_dir, 'train', sorghum_class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP8mz8g0UGSA"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model based on  DATASET2 architecture from the article\n",
        "def create_model(num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(28, 28, 1)),\n",
        "\n",
        "        # First Conv Block\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), strides=1, padding='same'),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), strides=1, padding='same'),\n",
        "\n",
        "        # Second Conv Block\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), strides=1, padding='same'),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), strides=1, padding='same'),\n",
        "\n",
        "        # Third Conv Block\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), strides=1, padding='same'),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2), strides=1, padding='same'),\n",
        "\n",
        "        # Flatten\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        tf.keras.layers.Dense(64),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "        # Output Layer\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9x8LDfKUmnQ"
      },
      "outputs": [],
      "source": [
        "# Function to save training history plot\n",
        "def save_training_history(history, crop_name, output_dir):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{crop_name} Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{crop_name} Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'{crop_name}_training_history.png'))\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Ydyy6_UtNw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to save confusion matrix\n",
        "def save_confusion_matrix(y_true, y_pred, class_names, crop_name, output_dir):\n",
        "    cm = confusion_matrix(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1))\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'{crop_name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'{crop_name}_confusion_matrix.png'))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LycMYX8QUVUX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Update the crops list to use the captured class names\n",
        "crops = [\n",
        "    {\n",
        "        'name': 'Maize',\n",
        "        'train_ds': maize_train,\n",
        "        'val_ds': maize_val,\n",
        "        'test_ds': maize_test,\n",
        "        'class_weights': maize_class_weights,\n",
        "        'num_classes': len(maize_class_names), # Ensure num_classes matches the captured list\n",
        "        'class_names': maize_class_names\n",
        "    },\n",
        "    {\n",
        "        'name': 'Rice',\n",
        "        'train_ds': rice_train,\n",
        "        'val_ds': rice_val,\n",
        "        'test_ds': rice_test,\n",
        "        'class_weights': rice_class_weights,\n",
        "        'num_classes': len(rice_class_names),\n",
        "        'class_names': rice_class_names\n",
        "    },\n",
        "    {\n",
        "        'name': 'Sorghum',\n",
        "        'train_ds': sorghum_train,\n",
        "        'val_ds': sorghum_val,\n",
        "        'test_ds': sorghum_test,\n",
        "        'class_weights': sorghum_class_weights,\n",
        "        'num_classes': len(sorghum_class_names),\n",
        "        'class_names': sorghum_class_names\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import os\n",
        "\n",
        "def train_and_save_model(crop):\n",
        "    \"\"\"Train and save model without test evaluation\"\"\"\n",
        "    crop_output_dir = os.path.join(output_base_dir, crop['name'])\n",
        "    os.makedirs(crop_output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nTraining model for {crop['name']}...\")\n",
        "\n",
        "    # Create and train the model\n",
        "    model = create_model(crop['num_classes'])\n",
        "\n",
        "    history = model.fit(\n",
        "        crop['train_ds'],\n",
        "        validation_data=crop['val_ds'],\n",
        "        epochs=30,\n",
        "        class_weight=crop['class_weights'],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save training history\n",
        "    save_training_history(history, crop['name'], crop_output_dir)\n",
        "\n",
        "    # Save training history data as JSON\n",
        "    with open(os.path.join(crop_output_dir, f'{crop[\"name\"]}_history.json'), 'w') as f:\n",
        "        json.dump(history.history, f)\n",
        "\n",
        "    # Save the model FIRST before any test evaluation\n",
        "    model.save(os.path.join(crop_output_dir, f'{crop[\"name\"]}_model.h5'))\n",
        "    print(f\"Model for {crop['name']} saved in {crop_output_dir}\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "al0xw3mC3Hjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set(model, crop):\n",
        "    \"\"\"Safe evaluation on test set\"\"\"\n",
        "    crop_output_dir = os.path.join(output_base_dir, crop['name'])\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nAttempting test evaluation for {crop['name']}...\")\n",
        "\n",
        "        # Safe test iteration\n",
        "        test_images, test_labels = [], []\n",
        "        for batch in crop['test_ds']:\n",
        "            try:\n",
        "                images, labels = batch\n",
        "                test_images.append(images.numpy())\n",
        "                test_labels.append(labels.numpy())\n",
        "            except Exception as e:\n",
        "                print(f\"Skipped a batch due to error: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if test_images:\n",
        "            test_images = np.concatenate(test_images, axis=0)\n",
        "            test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "            test_predictions = model.predict(test_images)\n",
        "\n",
        "            # Save classification report\n",
        "            report = classification_report(\n",
        "                np.argmax(test_labels, axis=1),\n",
        "                np.argmax(test_predictions, axis=1),\n",
        "                target_names=crop['class_names'],\n",
        "                output_dict=True\n",
        "            )\n",
        "            with open(os.path.join(crop_output_dir, f'{crop[\"name\"]}_classification_report.json'), 'w') as f:\n",
        "                json.dump(report, f)\n",
        "\n",
        "            # Save confusion matrix\n",
        "            save_confusion_matrix(test_labels, test_predictions, crop['class_names'], crop['name'], crop_output_dir)\n",
        "\n",
        "            print(f\"Test evaluation completed for {crop['name']}\")\n",
        "        else:\n",
        "            print(f\"Warning: No valid test batches processed for {crop['name']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Test evaluation failed for {crop['name']}: {str(e)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lAfw63aX28Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Maize\n",
        "maize_model, maize_history = train_and_save_model(crops[0])\n",
        "evaluate_on_test_set(maize_model, crops[0])\n",
        "del maize_model, maize_history\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n"
      ],
      "metadata": {
        "id": "F_xVO85o2-4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Process Rice\n",
        "rice_model, rice_history = train_and_save_model(crops[1])\n",
        "evaluate_on_test_set(rice_model, crops[1])\n",
        "del rice_model, rice_history\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n"
      ],
      "metadata": {
        "id": "Tt3YFL663ASS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4b9997-a2d3-46d5-d78e-25e4e95cddba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model for Rice...\n",
            "Epoch 1/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 11s/step - accuracy: 0.1608 - loss: 1.9607 - val_accuracy: 0.1671 - val_loss: 1.7905\n",
            "Epoch 2/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 244ms/step - accuracy: 0.2012 - loss: 1.7872 - val_accuracy: 0.2596 - val_loss: 1.7274\n",
            "Epoch 3/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 242ms/step - accuracy: 0.2273 - loss: 1.7274 - val_accuracy: 0.3265 - val_loss: 1.6482\n",
            "Epoch 4/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - accuracy: 0.1917 - loss: 1.7931 - val_accuracy: 0.1671 - val_loss: 1.7910\n",
            "Epoch 5/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.1744 - loss: 1.7900 - val_accuracy: 0.1877 - val_loss: 1.7811\n",
            "Epoch 6/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 237ms/step - accuracy: 0.1840 - loss: 1.7869 - val_accuracy: 0.3265 - val_loss: 1.7135\n",
            "Epoch 7/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 244ms/step - accuracy: 0.2523 - loss: 1.7053 - val_accuracy: 0.3008 - val_loss: 1.6176\n",
            "Epoch 8/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - accuracy: 0.2997 - loss: 1.6092 - val_accuracy: 0.3599 - val_loss: 1.5886\n",
            "Epoch 9/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - accuracy: 0.3105 - loss: 1.5772 - val_accuracy: 0.3805 - val_loss: 1.7017\n",
            "Epoch 10/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - accuracy: 0.3475 - loss: 1.5343 - val_accuracy: 0.4113 - val_loss: 1.7358\n",
            "Epoch 11/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 245ms/step - accuracy: 0.3954 - loss: 1.4544 - val_accuracy: 0.4293 - val_loss: 1.5926\n",
            "Epoch 12/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 246ms/step - accuracy: 0.4012 - loss: 1.4011 - val_accuracy: 0.3805 - val_loss: 1.8804\n",
            "Epoch 13/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 246ms/step - accuracy: 0.4412 - loss: 1.3562 - val_accuracy: 0.4499 - val_loss: 1.9394\n",
            "Epoch 14/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 242ms/step - accuracy: 0.4885 - loss: 1.2851 - val_accuracy: 0.4884 - val_loss: 1.5753\n",
            "Epoch 15/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 243ms/step - accuracy: 0.4727 - loss: 1.2912 - val_accuracy: 0.5116 - val_loss: 1.6651\n",
            "Epoch 16/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - accuracy: 0.4955 - loss: 1.2006 - val_accuracy: 0.5167 - val_loss: 1.6408\n",
            "Epoch 17/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 229ms/step - accuracy: 0.5134 - loss: 1.1666 - val_accuracy: 0.5450 - val_loss: 1.4988\n",
            "Epoch 18/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 232ms/step - accuracy: 0.5057 - loss: 1.1539 - val_accuracy: 0.4524 - val_loss: 2.0328\n",
            "Epoch 19/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - accuracy: 0.5308 - loss: 1.1169 - val_accuracy: 0.5553 - val_loss: 1.4766\n",
            "Epoch 20/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - accuracy: 0.5550 - loss: 1.0866 - val_accuracy: 0.5321 - val_loss: 1.7691\n",
            "Epoch 21/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - accuracy: 0.5516 - loss: 1.0791 - val_accuracy: 0.4961 - val_loss: 1.8002\n",
            "Epoch 22/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - accuracy: 0.6011 - loss: 0.9988 - val_accuracy: 0.4242 - val_loss: 2.6199\n",
            "Epoch 23/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - accuracy: 0.5799 - loss: 1.0386 - val_accuracy: 0.5553 - val_loss: 1.6736\n",
            "Epoch 24/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 245ms/step - accuracy: 0.5902 - loss: 0.9883 - val_accuracy: 0.5630 - val_loss: 1.5694\n",
            "Epoch 25/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 242ms/step - accuracy: 0.6108 - loss: 0.9310 - val_accuracy: 0.5193 - val_loss: 2.0661\n",
            "Epoch 26/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 237ms/step - accuracy: 0.6274 - loss: 0.9131 - val_accuracy: 0.5321 - val_loss: 1.9786\n",
            "Epoch 27/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - accuracy: 0.6109 - loss: 0.9398 - val_accuracy: 0.5450 - val_loss: 1.9081\n",
            "Epoch 28/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - accuracy: 0.6324 - loss: 0.8777 - val_accuracy: 0.5296 - val_loss: 1.8888\n",
            "Epoch 29/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 234ms/step - accuracy: 0.6593 - loss: 0.8328 - val_accuracy: 0.5296 - val_loss: 2.1125\n",
            "Epoch 30/30\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - accuracy: 0.6455 - loss: 0.8456 - val_accuracy: 0.5398 - val_loss: 1.9662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model for Rice saved in /content/drive/MyDrive/PERFORMANCECROPDATASET_Results/Rice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Sorghum\n",
        "sorghum_model, sorghum_history = train_and_save_model(crops[2])\n",
        "evaluate_on_test_set(sorghum_model, crops[2])\n",
        "del sorghum_model, sorghum_history\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "bEvzru1J3CZG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1HKlBX4wysOLA6H0Ywv8usQiiNIDJ-gvk",
      "authorship_tag": "ABX9TyPD/OHRuf4bymr9+pz7kn68",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}